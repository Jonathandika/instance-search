{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance Search Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "from src.helper.InstanceSearch import InstanceSearch\n",
    "from src.helper.FeatureExtractor import FeatureExtractor\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"query_path\": \"src/files/datasets/query/\",\n",
    "    \"query_box_path\": \"src/files/datasets/query_txt/\",\n",
    "    \"gallery_path\": \"src/files/datasets/gallery_4186/\",\n",
    "    \"feature_path\": \"src/files/features/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch = InstanceSearch(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loaded query files: {len(instanceSearch.query_ids)}\")\n",
    "print(f\"Loaded query boxes: {len(instanceSearch.query_boxes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helper.ModelWrapper import VGG16Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_vgg16 = FeatureExtractor(VGG16Extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_vgg16.extract_batch(source_path=config['gallery_path'], target_path=config['feature_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.set_feature_extractor(fe_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search(query_id = '27', k=40, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helper.ModelWrapper import VGG19Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_vgg19 = FeatureExtractor(VGG19Extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_vgg19.extract_batch(source_path=config['gallery_path'], target_path=config['feature_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.set_feature_extractor(fe_vgg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.feature_extractor.model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search(query_id = '27', k=40, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helper.ModelWrapper import CLIPExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_clip = FeatureExtractor(CLIPExtractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_clip.extract_batch(source_path=config['gallery_path'], target_path=config['feature_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.set_feature_extractor(fe_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.feature_extractor.model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search(query_id = '27', k=150, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP 336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helper.ModelWrapper import CLIPExtractor_336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_clip_336 = FeatureExtractor(CLIPExtractor_336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_clip_336.extract_batch(source_path=config['gallery_path'], target_path=config['feature_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.set_feature_extractor(fe_clip_336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.feature_extractor.model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search(query_id = '27', k=40, distance='euclidean', plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helper.ModelWrapper import ViTExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_vit = FeatureExtractor(ViTExtractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_vit.extract_batch(source_path=config['gallery_path'], target_path=config['feature_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.set_feature_extractor(fe_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.feature_extractor.model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search(query_id = '27', k=40, plot=True, distance='euclidean', query_expansion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dino V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helper.ModelWrapper import DinoV2Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_dino = FeatureExtractor(DinoV2Extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_dino.extract_batch(source_path=config['gallery_path'], target_path=config['feature_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.set_feature_extractor(fe_dino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.feature_extractor.model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search(query_id = '27', k=40, plot=True, distance='cosine', query_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reranking using local feature matching LightGlue + SuperPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightglue import LightGlue, SuperPoint, DISK\n",
    "from lightglue.utils import load_image, rbd\n",
    "from lightglue import viz2d\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "extractor = SuperPoint(max_num_keypoints=1024).eval().to(device)\n",
    "matcher = LightGlue(features='superpoint', depth_confidence=0.9, width_confidence=0.95).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# For each query image, show the top-20 most similar images\n",
    "for query_filename in tqdm(instanceSearch.query_filenames):\n",
    "    print(\"Query\", query_filename, \"...\")\n",
    "    \n",
    "    query_id = query_filename.split('.')[0]\n",
    "    \n",
    "    query = fe_clip.extract(config['query_path'] + query_id + '.jpg', bounding_box=instanceSearch.query_boxes[query_id])\n",
    "    \n",
    "    distances = {}\n",
    "    for i in tqdm(os.listdir('src/files/features_clip_L14/')):\n",
    "        if i.split('.')[-1] != 'npy':\n",
    "            continue\n",
    "        feature = np.load('src/files/features_clip_L14/' + i)\n",
    "        distances[i.replace('.npy', '.jpg')] = distance.euclidean(query, feature)\n",
    "\n",
    "    distances = dict(sorted(distances.items(), key=lambda item: item[1]))\n",
    "    \n",
    "    # Rerank using number of matches between the query and the gallery images\n",
    "    \n",
    "    reranked_distances = {}\n",
    "    for image in tqdm(list(distances.keys())[:40]):\n",
    "        img = load_image(config['gallery_path'] + image)\n",
    "        query_image = load_image(config['query_path'] + query_id + '.jpg')\n",
    "        \n",
    "        x, y, w, h = instanceSearch.query_boxes[query_id] # x, y, w, h\n",
    "        cropped_query_image = query_image[:, y:y+h, x:x+w]\n",
    "        \n",
    "        # Extract keypoints and descriptors\n",
    "        feats0 = extractor.extract(img.to(device))\n",
    "        feats1 = extractor.extract(cropped_query_image.to(device))\n",
    "        matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "        feats0, feats1, matches01 = [\n",
    "            rbd(x) for x in [feats0, feats1, matches01]\n",
    "        ]  # remove batch dimension\n",
    "\n",
    "        kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n",
    "        reranked_distances[image] = len(matches)\n",
    "        \n",
    "    reranked_distances = dict(sorted(reranked_distances.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    # Show the top-20 most similar images\n",
    "    plt.figure(figsize=(23, 4))\n",
    "    plt.subplot(2, 12, 1)\n",
    "    plt.imshow(Image.open(config['query_path'] + query_id + '.jpg'))\n",
    "    plt.title(f'Query Image {query_id}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    for i, (filename, dist) in enumerate(reranked_distances.items()):\n",
    "        if i >= 20:\n",
    "            break\n",
    "        img = Image.open(config['gallery_path'] + filename)\n",
    "        plt.subplot(2, 12, i+3)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'{filename} ({dist:.4f})')\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reranking using local feature matching SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each query image, show the top-20 most similar images\n",
    "for query_id in tqdm(instanceSearch.query_ids):\n",
    "    print(\"Query\", query_id, \"...\")\n",
    "    \n",
    "    query = fe_clip.extract(config['query_path'] + query_id + '.jpg', bounding_box=instanceSearch.query_boxes[query_id])\n",
    "    \n",
    "    distances = {}\n",
    "    for i in tqdm(os.listdir('src/files/features/features_clip_L14/')):\n",
    "        if i.split('.')[-1] != 'npy':\n",
    "            continue\n",
    "        feature = np.load('src/files/features/features_clip_L14/' + i)\n",
    "        distances[i.replace('.npy', '.jpg')] = distance.euclidean(query, feature)\n",
    "\n",
    "    distances = dict(sorted(distances.items(), key=lambda item: item[1]))\n",
    "    \n",
    "    # Rerank using number of matches using SIFT\n",
    "    \n",
    "    reranked_distances = {}\n",
    "    for image in tqdm(list(distances.keys())[:40]):\n",
    "        img = Image.open(config['gallery_path'] + image)\n",
    "        query_image = Image.open(config['query_path'] + query_id + '.jpg')\n",
    "        \n",
    "        x, y, w, h = instanceSearch.query_boxes[query_id]\n",
    "        cropped_query_image = query_image.crop([x, y, x + w, y + h])\n",
    "        \n",
    "        img = np.array(img)\n",
    "        cropped_query_image = np.array(cropped_query_image)\n",
    "        \n",
    "        # Extract keypoints and descriptors\n",
    "        sift = cv2.SIFT_create()\n",
    "        kp1, des1 = sift.detectAndCompute(img, None)\n",
    "        kp2, des2 = sift.detectAndCompute(cropped_query_image, None)\n",
    "        \n",
    "        # Match descriptors\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(des1, des2, k=2)\n",
    "        \n",
    "        # Apply ratio test\n",
    "        good = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good.append([m])\n",
    "                \n",
    "        reranked_distances[image] = len(good)/len(kp1)\n",
    "        \n",
    "    reranked_distances = dict(sorted(reranked_distances.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    # Show the top-20 most similar images\n",
    "    plt.figure(figsize=(23, 4))\n",
    "    plt.subplot(2, 12, 1)\n",
    "    plt.imshow(Image.open(config['query_path'] + query_id + '.jpg'))\n",
    "    plt.title(f'Query Image {query_id}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    for i, (filename, dist) in enumerate(reranked_distances.items()):\n",
    "        if i >= 20:\n",
    "            break\n",
    "        img = Image.open(config['gallery_path'] + filename)\n",
    "        plt.subplot(2, 12, i+3)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'{filename} ({dist:.4f})')\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug(img):\n",
    "    # perspective change to augment query data\n",
    "    transformed_imgs = [img]\n",
    "\n",
    "    height, width, channel = img.shape\n",
    "    pts = np.float32([[0, 0], [width, 0], [width, height], [0, height]])\n",
    "\n",
    "    # eight different perspective transformations\n",
    "    pts1 = np.float32([[0, 0], [0.8 * width, height * 0.025], [0.8 * width, 0.975 * height], [0, height]])\n",
    "    pts2 = np.float32([[0.2 * width, 0.025 * height], [width, 0], [width, height], [0.2 * width, 0.975 * height]])\n",
    "    pts3 = np.float32([[0, 0], [width, 0], [0.975 * width, 0.8 * height], [0.025 * width, 0.8 * height]])\n",
    "    pts4 = np.float32([[0.025 * width, 0.2 * height], [0.975 * width, 0.2 * height], [width, height], [0, height]])\n",
    "\n",
    "    pts5 = np.float32([[0, 0], [0.6 * width, height * 0.1], [0.6 * width, 0.9 * height], [0, height]])\n",
    "    pts6 = np.float32([[0.4 * width, 0.1 * height], [width, 0], [width, height], [0.4 * width, 0.9 * height]])\n",
    "    pts7 = np.float32([[0, 0], [width, 0], [0.9 * width, 0.6 * height], [0.1 * width, 0.6 * height]])\n",
    "    pts8 = np.float32([[0.1 * width, 0.4 * height], [0.9 * width, 0.4 * height], [width, height], [0, height]])\n",
    "    \n",
    "    \n",
    "\n",
    "    all_target_pts = [pts1, pts2, pts3, pts4, pts5, pts6, pts7, pts8]\n",
    "\n",
    "    for idx, target in enumerate(all_target_pts):\n",
    "        # compute the perspective transform matrix and then apply it\n",
    "        M = cv2.getPerspectiveTransform(pts, target)\n",
    "        transformed = cv2.warpPerspective(img, M, (width, height))\n",
    "        transformed_imgs.append(transformed)\n",
    "        \n",
    "    return transformed_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(config['query_path'] + '27.jpg')\n",
    "\n",
    "x, y, w, h = instanceSearch.query_boxes['27']\n",
    "cropped_img = img.crop([x, y, x + w, y + h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_imgs = data_aug(np.array(cropped_img))\n",
    "\n",
    "for i in aug_imgs:\n",
    "    plt.imshow(i)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP + Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helper.ModelWrapper import CLIPExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_clip = FeatureExtractor(CLIPExtractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.set_feature_extractor(fe_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.feature_extractor.model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search(query_id = '27', k=150, plot=True, query_expansion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min\n",
    "res = instanceSearch.search_all(query_expansion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean\n",
    "res = instanceSearch.search_all(query_expansion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search_all(query_augmentation=True, query_expansion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search_all(query_augmentation=True, query_expansion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP 336 + QA + QE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helper.ModelWrapper import CLIPExtractor_336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_clip_336 = FeatureExtractor(CLIPExtractor_336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.set_feature_extractor(fe_clip_336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.feature_extractor.model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search(query_id = '27', k=40, distance='euclidean', plot=True, query_expansion=True, query_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search_all(query_expansion=True, query_augmentation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP 336 + QA 2.0 + QE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helper.ModelWrapper import CLIPExtractor_336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_clip_336 = FeatureExtractor(CLIPExtractor_336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.set_feature_extractor(fe_clip_336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.feature_extractor.model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search(query_id = '27', k=40, distance='euclidean', plot=True, query_augmentation=True, query_expansion=True, query_expansion_2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search_all(query_expansion=True, query_augmentation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19 with Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helper.ModelWrapper import VGG19Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_vgg19 = FeatureExtractor(VGG19Extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_vgg19.extract_batch(source_path=config['gallery_path'], target_path=config['feature_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.set_feature_extractor(fe_vgg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearch.feature_extractor.model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search(query_id = '27', k=40, plot=True, query_expansion=True, query_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearch.search_all(query_augmentation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helper.ModelWrapper import VGG19Extractor, CLIPExtractor_336\n",
    "fe_clip_336 = FeatureExtractor(CLIPExtractor_336)\n",
    "fe_vgg19 = FeatureExtractor(VGG19Extractor)\n",
    "\n",
    "class InstanceSearchCombined(InstanceSearch):\n",
    "    \n",
    "    def search(self, \n",
    "               query_id: str, \n",
    "               k: int = 10, \n",
    "               plot = False, \n",
    "               distance='euclidean', \n",
    "               query_augmentation: bool = False,\n",
    "               query_expansion: bool = False,\n",
    "               query_expansion_2: bool = False) -> list:\n",
    "        \n",
    "        \n",
    "\n",
    "        queries_vgg19 = fe_vgg19.extract(img_path=self.config['query_path'] + query_id + '.jpg', \n",
    "                                                 bounding_box=self.query_boxes[query_id],\n",
    "                                                 aug=query_augmentation)\n",
    "        \n",
    "        queries_clip = fe_clip_336.extract(img_path=self.config['query_path'] + query_id + '.jpg', \n",
    "                                                 bounding_box=self.query_boxes[query_id],\n",
    "                                                 aug=query_augmentation)\n",
    "        \n",
    "        distance_calculator = self.get_distance_calculator(distance)\n",
    "        \n",
    "        feature_path_vgg19 = os.path.join(self.config['feature_path'], ('features_' + fe_vgg19.model.name))\n",
    "        feature_path_clip = os.path.join(self.config['feature_path'], ('features_' + fe_clip_336.model.name))\n",
    "        \n",
    "        distances = {}\n",
    "        for i, j in tqdm(zip(os.listdir(feature_path_vgg19), os.listdir(feature_path_clip))):\n",
    "            \n",
    "            feature_vgg19 = np.load(os.path.join(feature_path_vgg19, i))\n",
    "            \n",
    "            d = []\n",
    "            for query in queries_vgg19: \n",
    "                d.append(distance_calculator(query, feature_vgg19))\n",
    "            distance_vgg19 = np.mean(d)\n",
    "            \n",
    "            feature_clip = np.load(os.path.join(feature_path_clip, j))\n",
    "            \n",
    "            d = []\n",
    "            for query in queries_clip:\n",
    "                d.append(distance_calculator(query, feature_clip))\n",
    "            distance_clip = np.mean(d)\n",
    "                                \n",
    "            distances[i.split('.')[0]] = (distance_vgg19 + distance_clip) / 2\n",
    "\n",
    "        distances = dict(sorted(distances.items(), key=lambda item: item[1]))\n",
    "        \n",
    "        feature_path = os.path.join(self.config['feature_path'], ('features_' + self.feature_extractor.model.name))\n",
    "        \n",
    "        new_distances = {}\n",
    "        \n",
    "        if query_expansion:\n",
    "            \n",
    "            # Get the second closest image\n",
    "            second_closest_ids = list(distances.keys())[:10]\n",
    "            \n",
    "            # Query using the second closest image\n",
    "            second_query = []\n",
    "            for id in second_closest_ids:\n",
    "                second_query.extend(self.feature_extractor.extract(img_path=self.config['gallery_path'] + id + '.jpg'))\n",
    "            \n",
    "            for i in tqdm(os.listdir(feature_path)):\n",
    "                \n",
    "                if i.split('.')[-1] != 'npy':\n",
    "                    continue\n",
    "                feature = np.load(os.path.join(feature_path, i))\n",
    "                \n",
    "                d = []\n",
    "                for query in second_query:\n",
    "                    d.append(distance_calculator(query, feature))\n",
    "                \n",
    "                # Get mean distance\n",
    "                d.append(distances[i.split('.')[0]])\n",
    "                new_distances[i.split('.')[0]] = np.mean(d)\n",
    "                \n",
    "            new_distances = dict(sorted(new_distances.items(), key=lambda item: item[1]))\n",
    "            distances = new_distances\n",
    "\n",
    "\n",
    "        if plot:\n",
    "            \n",
    "            num_rows = (k + 2) // 12 + 1\n",
    "            num_cols = 12\n",
    "\n",
    "            figsize = (num_cols * 2.25, num_rows * 2)\n",
    "            \n",
    "            plt.figure(figsize=figsize)\n",
    "            plt.subplot(num_rows, num_cols, 1)\n",
    "            plt.imshow(Image.open(self.config['query_path'] + query_id + '.jpg'))\n",
    "            plt.title(f'Query Image {query_id}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            for i, (query_id, dist) in enumerate(distances.items()):\n",
    "                if i >= k:\n",
    "                    break\n",
    "                img = Image.open(self.config['gallery_path'] + query_id + '.jpg')\n",
    "                plt.subplot(num_rows, 12, i+3)\n",
    "                plt.imshow(img)\n",
    "                plt.title(f'{query_id} ({dist:.3f})')\n",
    "                plt.axis('off')\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "        return list(distances.keys())[:k] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceSearchCombined = InstanceSearchCombined(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_clip_336 = FeatureExtractor(CLIPExtractor_336)\n",
    "instanceSearchCombined.set_feature_extractor(fe_clip_336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearchCombined.search(query_id = '27', k=40, distance='cosine', plot=True, query_expansion=True, query_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearchCombined.search_all(query_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = instanceSearchCombined.search_all(query_augmentation=True, query_expansion=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
